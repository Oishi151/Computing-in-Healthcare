{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "\n",
    "def read_sequences(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return [line.strip() for line in f if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found.\")\n",
    "        #return generate_sample_data()\n",
    "\n",
    "positive_sequences = read_sequences(\"dnase_seq_output_positive_trimmed.txt\")\n",
    "negative_sequences = read_sequences(\"negative_file.txt\")\n",
    "\n",
    "labeled_data = [(seq, 1) for seq in positive_sequences] + [(seq, 0) for seq in negative_sequences]\n",
    "random.shuffle(labeled_data)\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "    mapping = {'A': [1,0,0,0], 'C': [0,1,0,0], 'G': [0,0,1,0], 'T': [0,0,0,1]}\n",
    "    return np.array([mapping[base] for base in sequence.upper()])\n",
    "\n",
    "class DNADataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.sequences = []\n",
    "        self.labels = []\n",
    "        for seq, label in data:\n",
    "            self.sequences.append(one_hot_encode(seq))\n",
    "            self.labels.append(label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.sequences[idx]), torch.tensor(self.labels[idx])\n",
    "    \n",
    "class AlexNet1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet1D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(4, 96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 2, 256),  # Flattened size: 256 * 2\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class NiN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NiN1D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(4, 96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(96, 96, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(96, 96, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(96, 256, kernel_size=5, padding=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(384, 384, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(384, 384, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(384 * 3, 256),  # Flattened size: 384 * 3\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "def train_model(model, train_loader, test_loader, optimizer, criterion, epochs=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    accuracies = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        accuracy = 100. * correct / total\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'Epoch {epoch+1}, Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return accuracies, all_preds, all_labels\n",
    "\n",
    "def main():\n",
    "    dataset = DNADataset(labeled_data)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    configs = [\n",
    "        (\"AlexNet-0.01-16\", AlexNet1D(), 0.01, 16),\n",
    "        (\"AlexNet-0.0001-64\", AlexNet1D(), 0.0001, 64),\n",
    "        (\"NiN-0.0001-16\", NiN1D(), 0.0001, 16),\n",
    "        (\"NiN-0.01-64\", NiN1D(), 0.01, 64)\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    all_conf_matrices = {}\n",
    "    for name, model, lr, batch_size in configs:\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "        print(f\"\\nTraining {name} with batch size {batch_size} and learning rate {lr}...\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        accuracies, all_preds, all_labels = train_model(model, train_loader, test_loader, optimizer, criterion)\n",
    "        results[name] = accuracies\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "        all_conf_matrices[name] = conf_matrix\n",
    "\n",
    "    # Plot accuracy vs. epochs\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for name, accuracies in results.items():\n",
    "        plt.plot(range(1, len(accuracies) + 1), accuracies, label=name)\n",
    "    plt.title(\"Accuracy vs. Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Display confusion matrices\n",
    "    for name, conf_matrix in all_conf_matrices.items():\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0, 1])\n",
    "        disp.plot(cmap='Blues', values_format='d')\n",
    "        plt.title(f\"Confusion Matrix for {name}\")\n",
    "        plt.show()\n",
    "\n",
    "# Run the main function\n",
    "results = main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
